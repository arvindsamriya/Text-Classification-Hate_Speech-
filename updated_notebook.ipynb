{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description \n",
    "The objective of this project is to detect the racist and sexist comments from amazon reviews or does a review contain any hate speech in it,we will classify these reviews.\n",
    "We will use a Training sample to build a model and use that model on a test dataset to predict the labels on that dataset and find the accuracy of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this whole process we will use the amazon review 'txt' file to build the system and in this file we have 10000 examples, We \n",
    "will follow the following components to get the result-\n",
    "#### -Dataset Preparation\n",
    "#### -Feature Extraction\n",
    "#### - Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection,preprocessing,svm,metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      0\n",
      "0     __label__2 Stuning even for the non-gamer: Thi...\n",
      "1     __label__2 The best soundtrack ever to anythin...\n",
      "2     __label__2 Amazing!: This soundtrack is my fav...\n",
      "3     __label__2 Excellent Soundtrack: I truly like ...\n",
      "4     __label__2 Remember, Pull Your Jaw Off The Flo...\n",
      "...                                                 ...\n",
      "9995  __label__2 A revelation of life in small town ...\n",
      "9996  __label__2 Great biography of a very interesti...\n",
      "9997  __label__1 Interesting Subject; Poor Presentat...\n",
      "9998  __label__1 Don't buy: The box looked used and ...\n",
      "9999  __label__2 Beautiful Pen and Fast Delivery.: T...\n",
      "\n",
      "[10000 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__2 Stuning even for the non-gamer: Thi...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__2 The best soundtrack ever to anythin...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__2 Amazing!: This soundtrack is my fav...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__2 Excellent Soundtrack: I truly like ...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__2 Remember, Pull Your Jaw Off The Flo...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>__label__2 A revelation of life in small town ...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>A revelation of life in small town America in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>__label__2 Great biography of a very interesti...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Great biography of a very interesting journali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>__label__1 Interesting Subject; Poor Presentat...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>Interesting Subject; Poor Presentation: You'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>__label__1 Don't buy: The box looked used and ...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>Don't buy: The box looked used and it is obvio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>__label__2 Beautiful Pen and Fast Delivery.: T...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Beautiful Pen and Fast Delivery.: The pen was ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0       label  \\\n",
       "0     __label__2 Stuning even for the non-gamer: Thi...  __label__2   \n",
       "1     __label__2 The best soundtrack ever to anythin...  __label__2   \n",
       "2     __label__2 Amazing!: This soundtrack is my fav...  __label__2   \n",
       "3     __label__2 Excellent Soundtrack: I truly like ...  __label__2   \n",
       "4     __label__2 Remember, Pull Your Jaw Off The Flo...  __label__2   \n",
       "...                                                 ...         ...   \n",
       "9995  __label__2 A revelation of life in small town ...  __label__2   \n",
       "9996  __label__2 Great biography of a very interesti...  __label__2   \n",
       "9997  __label__1 Interesting Subject; Poor Presentat...  __label__1   \n",
       "9998  __label__1 Don't buy: The box looked used and ...  __label__1   \n",
       "9999  __label__2 Beautiful Pen and Fast Delivery.: T...  __label__2   \n",
       "\n",
       "                                                   Text  \n",
       "0     Stuning even for the non-gamer: This sound tra...  \n",
       "1     The best soundtrack ever to anything.: I'm rea...  \n",
       "2     Amazing!: This soundtrack is my favorite music...  \n",
       "3     Excellent Soundtrack: I truly like this soundt...  \n",
       "4     Remember, Pull Your Jaw Off The Floor After He...  \n",
       "...                                                 ...  \n",
       "9995  A revelation of life in small town America in ...  \n",
       "9996  Great biography of a very interesting journali...  \n",
       "9997  Interesting Subject; Poor Presentation: You'd ...  \n",
       "9998  Don't buy: The box looked used and it is obvio...  \n",
       "9999  Beautiful Pen and Fast Delivery.: The pen was ...  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will convert the raw data into a meaning full and informative dataset\n",
    "df=pd.read_csv('review.txt',sep=('\\n'),header=None)\n",
    "print(df)\n",
    "#df.iloc[:,0]=df.iloc[:,0].str.lower()\n",
    "df['label']=''\n",
    "df['Text']=''\n",
    "texts=[]\n",
    "for i in df.index:\n",
    "    body=str(df.iloc[i,0]).split()\n",
    "    df['label'][i]=body[0]\n",
    "    df['Text'][i]=\" \".join(body[1:])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction using TFidf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= model_selection.train_test_split(df['Text'],df['label'])\n",
    "#split the data into test and training datasets\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train= encoder.fit_transform(y_train)\n",
    "y_test= encoder.fit_transform(y_test)\n",
    "#we transform y_train and y_test into the binary class according to the labels.\n",
    "tfidf=TfidfVectorizer(min_df=10,max_df=0.99,ngram_range=(1,2),stop_words='english').fit(x_train)\n",
    "#we have use stopwords like he,are,is etc these words don't bring any feature to our dataset.\n",
    "#min_df removes words which are only present in less than 10 documents in the whole x_train.\n",
    "#max_df removes words which are present in 99% of the x_train documents.\n",
    "x_train=tfidf.transform(x_train)\n",
    "x_test=tfidf.transform(x_test)\n",
    "#feature extraction is completed here.\n",
    "#tfidf.get_feature_names() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df=pd.DataFrame(x_train.todense(),columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different ML Models and Model Selection\n",
    "We have extracted features and labels dataset, and now we will apply different ML models on the training dataset and calculate the accuracy for each of them.\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- Support Vector Machine(SVM)\n",
    "- Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "gridval={'alpha':[0.001,.01,.1,1,10]}\n",
    "model=MultinomialNB()\n",
    "grid=GridSearchCV(model,param_grid=gridval,scoring='accuracy')\n",
    "grid.fit(x_train,y_train)\n",
    "pred= grid.predict(x_test)\n",
    "accuracy_mnb=accuracy_score(y_test,pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "gridval={'C':[0.0001,0.001,.01,.1,1,10]}\n",
    "model=LogisticRegression()\n",
    "grid=GridSearchCV(model,param_grid=gridval,scoring='accuracy')\n",
    "grid.fit(x_train,y_train)\n",
    "pred= grid.predict(x_test)\n",
    "accuracy_lrg=accuracy_score(y_test,pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine (SVM)\n",
    "#gridval={'gamma':[0.0001,0.001,.01,.1,1,10],'C':[0.0001,0.001,.01,.1,1,10]}\n",
    "model=SVC(kernel='rbf')\n",
    "#grid=GridSearchCV(model,param_grid=gridval,scoring='accuracy')\n",
    "#grid.fit(x_train,y_train)\n",
    "#pred= grid.predict(x_test)\n",
    "model.fit(x_train,y_train)\n",
    "pred=model.predict(x_test)\n",
    "accuracy_svm=accuracy_score(y_test,pred)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model(RFM)\n",
    "model=RandomForestClassifier()\n",
    "#gridval={'n_estimators':[10,100,200,300,400,500]}\n",
    "#grid=GridSearchCV(model,param_grid=gridval,scoring='accuracy')\n",
    "#grid.fit(x_train,y_train)\n",
    "model.fit(x_train,y_train)\n",
    "#pred= grid.predict(x_test)\n",
    "pred=model.predict(x_test)\n",
    "accuracy_rfm=accuracy_score(y_test,pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies of Different Models\n",
      "Naive Bayer: 85.28\n",
      "Logistic Regression: 85.92\n",
      "Support Vector Machine(SVM):85.88\n",
      "Random Forest Model: 82.96\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Result\n",
    "#Now we have accuracy of different models-\n",
    "print('Accuracies of Different Models\\nNaive Bayer: {}\\nLogistic Regression: {}\\nSupport Vector Machine(SVM):{}\\nRandom Forest Model: {}\\n '.format(accuracy_mnb,accuracy_lrg,accuracy_svm,accuracy_rfm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
