{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description \n",
    "The objective of this project is to detect the racist and sexist comments from amazon reviews or does a review contain any hate speech in it,we will classify these reviews.\n",
    "We will use a Training sample to build a model and use that model on a test dataset to predict the labels on that dataset and find the accuracy of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this whole process we will use the amazon review 'txt' file to build the system and in this file we have 10000 examples, We \n",
    "will follow the following components to get the result-\n",
    "#### -Dataset Preparation\n",
    "#### -Feature Extraction\n",
    "#### - Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection,preprocessing,svm,metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('review.txt',sep=('\\n'),header=None)\n",
    "#df.iloc[:,0]=df.iloc[:,0].str.lower()\n",
    "df['label']=''\n",
    "df['Text']=''\n",
    "texts=[]\n",
    "for i in df.index:\n",
    "    body=str(df.iloc[i,0]).split()\n",
    "    df['label'][i]=body[0]\n",
    "    df['Text'][i]=\" \".join(body[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction using TFidf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= model_selection.train_test_split(df['Text'],df['label'])\n",
    "#split the data into test and training datasets\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train= encoder.fit_transform(y_train)\n",
    "y_test= encoder.fit_transform(y_test)\n",
    "#we transform y_train and y_test into the binary class according to the labels.\n",
    "tfidf=TfidfVectorizer(min_df=10,max_df=0.99,ngram_range=(1,2),max_features=5000,stop_words='english')\n",
    "#we have use stopwords like he,are,is etc these words don't bring any feature to our dataset.\n",
    "#min_df removes words which are only present in less than 10 documents in the whole x_train.\n",
    "#max_df removes words which are present in 99% of the x_train documents.\n",
    "x_train=tfidf.fit_transform(x_train)\n",
    "x_test=tfidf.transform(x_test)\n",
    "\n",
    "#feature extraction is completed here.\n",
    "# tfidf.get_feature_names() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different ML Models\n",
    "We have extracted features and labels dataset, and now we will apply different ML models on the training dataset and calculate the accuracy for each of them.\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- Support Vector Machine(SVM)\n",
    "- Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "\n",
    "mnb=MultinomialNB()\n",
    "mnb.fit(x_train,y_train)\n",
    "pred_mnb= mnb.predict(x_test)\n",
    "accuracy_mnb=np.mean(pred_mnb==y_test)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "lrg=LogisticRegression()\n",
    "lrg.fit(x_train,y_train)\n",
    "pred_lrg= lrg.predict(x_test)\n",
    "accuracy_lrg=np.mean(pred_lrg==y_test)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine (SVM)\n",
    "svm=LinearSVC()\n",
    "svm.fit(x_train,y_train)\n",
    "pred_svm= svm.predict(x_test)\n",
    "accuracy_svm=np.mean(pred_svm==y_test)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model(RFM)\n",
    "rfm=RandomForestClassifier()\n",
    "rfm.fit(x_train,y_train)\n",
    "pred_rfm= rfm.predict(x_test)\n",
    "accuracy_rfm=np.mean(pred_rfm==y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies of Different Models\n",
      "Naive Bayer: 83.76\n",
      "Logistic Regression: 85.68\n",
      "Support Vector Machine(SVM):85.16\n",
      "Random Forest Model: 83.28\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Result\n",
    "#Now we have accuracy of different models-\n",
    "print('Accuracies of Different Models\\nNaive Bayer: {}\\nLogistic Regression: {}\\nSupport Vector Machine(SVM):{}\\nRandom Forest Model: {}\\n '.format(accuracy_mnb,accuracy_lrg,accuracy_svm,accuracy_rfm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
